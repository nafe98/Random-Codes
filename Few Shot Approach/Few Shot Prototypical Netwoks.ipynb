{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afd8d918-227f-4199-9292-2b10fd78f3ff",
   "metadata": {},
   "source": [
    "# About Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03ff036-2a12-4adc-9230-6d6bdce2513b",
   "metadata": {},
   "source": [
    "The dataset contains EEG signals from 11 subjects with labels of alert and drowsy. It can be opened with Matlab. We extracted the data for our own research purpose from another public dataset:\n",
    "\n",
    "Cao, Z., et al., Multi-channel EEG recordings during a sustained-attention driving task. Scientific data, 2019. 6(1): p. 1-8.\n",
    "\n",
    "If you find the dataset useful, please give credits to their works.\n",
    "\n",
    "The details on how the data were extracted are described in our paper:\n",
    "\n",
    "\"Jian Cui, Zirui Lan, Yisi Liu, Ruilin Li, Fan Li, Olga Sourina, Wolfgang MÃ¼ller-Wittig, A Compact and Interpretable Convolutional Neural Network for Cross-Subject Driver Drowsiness Detection from Single-Channel EEG, Methods, 2021, ISSN 1046-2023, https://doi.org/10.1016/j.ymeth.2021.04.017.\"\n",
    "\n",
    "The codes of the paper above are accessible from:\n",
    "\n",
    "https://github.com/cuijiancorbin/A-Compact-and-Interpretable-Convolutional-Neural-Network-for-Single-Channel-EEG\n",
    "\n",
    "The data file contains 3 variables and they are EEGsample, substate and subindex.\n",
    "\n",
    "\"EEGsample\" contains 2022 EEG samples of size 20x384 from 11 subjects. Each sample is a 3s EEG data with 128Hz from 30 EEG channels.\n",
    "\"subindex\" is an array of 2022x1. It contains the subject indexes from 1-11 corresponding to each EEG sample.\n",
    "\"substate\" is an array of 2022x1. It contains the labels of the samples. 0 corresponds to the alert state and 1 correspond to the drowsy state.\n",
    "\n",
    "The unbalanced version of this dataset is accessible from:\n",
    "https://figshare.com/articles/dataset/EEG_driver_drowsiness_dataset_unbalanced_/16586957"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaf5de7-5868-410c-a1ae-c2d4e73af474",
   "metadata": {},
   "source": [
    "# Few Shot Prototypical Netwoks on EEG Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ca7549-bb8a-4b37-b1ad-541343a139cf",
   "metadata": {},
   "source": [
    "https://spotintelligence.com/2023/06/29/few-shot-learning/\n",
    "\n",
    "https://towardsdatascience.com/few-shot-learning-with-prototypical-networks-87949de03ccd\n",
    "\n",
    "https://arxiv.org/abs/1703.05175\n",
    "\n",
    "https://colab.research.google.com/github/cnielly/prototypical-networks-omniglot/blob/master/prototypical_networks_pytorch_omniglot.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ca9cae-5627-45a9-a8c1-59315042b7de",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3a3fdd5-df06-4ca2-ba7f-a19dfc340b73",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _imaging: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ndimage\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\matplotlib\\__init__.py:187\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 187\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sanitize_sequence\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\matplotlib\\rcsetup.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BackendFilter, backend_registry\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fontconfig_pattern\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\matplotlib\\colors.py:52\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumbers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Real\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mPngImagePlugin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PngInfo\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\PIL\\Image.py:88\u001b[0m\n\u001b[0;32m     79\u001b[0m MAX_IMAGE_PIXELS: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;66;03m# If the _imaging C module is not present, Pillow will not load.\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# Note that other modules should not refer to _imaging directly;\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# import Image and use the Image.core variable instead.\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;66;03m# Also note that Image.core is not a publicly documented interface,\u001b[39;00m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# and should be considered private and subject to change.\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _imaging \u001b[38;5;28;01mas\u001b[39;00m core\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m __version__ \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(core, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPILLOW_VERSION\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     91\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     92\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe _imaging extension was built for another version of Pillow or PIL:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCore version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mgetattr\u001b[39m(core,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPILLOW_VERSION\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPillow version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     95\u001b[0m         )\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _imaging: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762f8fb2-764f-4786-80ca-ba8cb67705a7",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2a6795f-6f1d-4213-b101-2fbd3cc99e52",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_train.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_train.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m X_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_test.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "X_train = np.load('X_train.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e3d811-6c33-49c0-a73b-a7a092e8e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset shapes\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc22772a-d58f-40b7-8905-72de5af39dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b8c08-326e-4dc6-a877-3e32ddf8f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_sample(n_way, n_support, n_query, datax, datay):\n",
    "    \"\"\"\n",
    "    Picks random sample of size n_support+n_query, for n_way classes\n",
    "    Args:\n",
    "        n_way (int): number of classes in a classification task\n",
    "        n_support (int): number of labeled examples per class in the support set\n",
    "        n_query (int): number of labeled examples per class in the query set\n",
    "        datax (np.array): dataset of EEG samples\n",
    "        datay (np.array): dataset of labels\n",
    "    Returns:\n",
    "        (dict) of:\n",
    "            (torch.Tensor): sample of EEG data. Size (n_way, n_support+n_query, (dim))\n",
    "            (int): n_way\n",
    "            (int): n_support\n",
    "            (int): n_query\n",
    "    \"\"\"\n",
    "    sample = []\n",
    "    K = np.random.choice(np.unique(datay), n_way, replace=False)\n",
    "    for cls in K:\n",
    "        datax_cls = datax[datay == cls]\n",
    "        perm = np.random.permutation(datax_cls)\n",
    "        sample_cls = perm[:(n_support+n_query)]\n",
    "        sample.append(sample_cls)\n",
    "    sample = np.array(sample)\n",
    "    sample = torch.from_numpy(sample).float()\n",
    "    return {\n",
    "        'EEG': sample,\n",
    "        'n_way': n_way,\n",
    "        'n_support': n_support,\n",
    "        'n_query': n_query\n",
    "    }\n",
    "\n",
    "def display_sample(sample):\n",
    "    \"\"\"\n",
    "    Displays sample in a grid\n",
    "    Args:\n",
    "        sample (torch.Tensor): sample of EEG data to display\n",
    "    \"\"\"\n",
    "    # Flatten the sample to 2D for display\n",
    "    sample_2D = sample.view(sample.shape[0]*sample.shape[1], -1)\n",
    "    plt.figure(figsize=(16, 7))\n",
    "    plt.imshow(sample_2D, aspect='auto', cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "n_way = 2\n",
    "n_support = 5\n",
    "n_query = 5\n",
    "sample_example = extract_sample(n_way, n_support, n_query, X_train, y_train)\n",
    "display_sample(sample_example['EEG'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b31648-e26d-4ab5-9ca3-563d11a0bd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class ProtoNet(nn.Module):\n",
    "    def __init__(self, encoder):\n",
    "        super(ProtoNet, self).__init__()\n",
    "        self.encoder = encoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "def load_protonet_conv(**kwargs):\n",
    "    \"\"\"\n",
    "    Loads the prototypical network model\n",
    "    Arg:\n",
    "        x_dim (tuple): dimension of input EEG data (channels, length)\n",
    "        hid_dim (int): dimension of hidden layers in conv blocks\n",
    "        z_dim (int): dimension of embedded EEG data\n",
    "    Returns:\n",
    "        Model (Class ProtoNet)\n",
    "    \"\"\"\n",
    "    x_dim = kwargs['x_dim']\n",
    "    hid_dim = kwargs['hid_dim']\n",
    "    z_dim = kwargs['z_dim']\n",
    "\n",
    "    def conv_block(in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2)\n",
    "        )\n",
    "    \n",
    "    encoder = nn.Sequential(\n",
    "        conv_block(x_dim[0], hid_dim),\n",
    "        conv_block(hid_dim, hid_dim),\n",
    "        conv_block(hid_dim, hid_dim),\n",
    "        conv_block(hid_dim, z_dim),\n",
    "        Flatten()\n",
    "    )\n",
    "    \n",
    "    return ProtoNet(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d174517-5245-4789-8ada-28c324f3f0a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 127] The specified procedure could not be found. Error loading \"C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\torch\\__init__.py:132\u001b[0m\n\u001b[0;32m    130\u001b[0m     err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(last_error)\n\u001b[0;32m    131\u001b[0m     err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 132\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 127] The specified procedure could not be found. Error loading \"C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def euclidean_dist(x, y):\n",
    "    \"\"\"\n",
    "    Compute euclidean distance between two tensors\n",
    "    Args:\n",
    "        x: tensor of shape (n, d)\n",
    "        y: tensor of shape (m, d)\n",
    "    Returns:\n",
    "        dist: tensor of shape (n, m)\n",
    "    \"\"\"\n",
    "    n = x.size(0)\n",
    "    m = y.size(0)\n",
    "    d = x.size(1)\n",
    "    assert d == y.size(1)\n",
    "    \n",
    "    x = x.unsqueeze(1).expand(n, m, d)\n",
    "    y = y.unsqueeze(0).expand(n, m, d)\n",
    "    \n",
    "    return torch.pow(x - y, 2).sum(2)\n",
    "\n",
    "class ProtoNet(nn.Module):\n",
    "    def __init__(self, encoder):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            encoder : CNN encoding the EEG samples\n",
    "            n_way (int): number of classes in a classification task\n",
    "            n_support (int): number of labeled examples per class in the support set\n",
    "            n_query (int): number of labeled examples per class in the query set\n",
    "        \"\"\"\n",
    "        super(ProtoNet, self).__init__()\n",
    "        self.encoder = encoder.cuda()\n",
    "\n",
    "    def set_forward_loss(self, sample):\n",
    "        \"\"\"\n",
    "        Computes loss, accuracy and output for classification task\n",
    "        Args:\n",
    "            sample (torch.Tensor): shape (n_way, n_support+n_query, (dim)) \n",
    "        Returns:\n",
    "            torch.Tensor: shape(2), loss, accuracy and y_hat\n",
    "        \"\"\"\n",
    "        sample_EEG = sample['EEG'].cuda()\n",
    "        n_way = sample['n_way']\n",
    "        n_support = sample['n_support']\n",
    "        n_query = sample['n_query']\n",
    "\n",
    "        x_support = sample_EEG[:, :n_support]\n",
    "        x_query = sample_EEG[:, n_support:]\n",
    "\n",
    "        # target indices are 0 ... n_way-1\n",
    "        target_inds = torch.arange(0, n_way).view(n_way, 1, 1).expand(n_way, n_query, 1).long()\n",
    "        target_inds = Variable(target_inds, requires_grad=False)\n",
    "        target_inds = target_inds.cuda()\n",
    "\n",
    "        # encode EEG samples of the support and the query set\n",
    "        x = torch.cat([x_support.contiguous().view(n_way * n_support, *x_support.size()[2:]),\n",
    "                       x_query.contiguous().view(n_way * n_query, *x_query.size()[2:])], 0)\n",
    "\n",
    "        z = self.encoder.forward(x)\n",
    "        z_dim = z.size(-1)  # usually 64\n",
    "        z_proto = z[:n_way*n_support].view(n_way, n_support, z_dim).mean(1)\n",
    "        z_query = z[n_way*n_support:]\n",
    "\n",
    "        # compute distances\n",
    "        dists = euclidean_dist(z_query, z_proto)\n",
    "\n",
    "        # compute probabilities\n",
    "        log_p_y = F.log_softmax(-dists, dim=1).view(n_way, n_query, -1)\n",
    "\n",
    "        loss_val = -log_p_y.gather(2, target_inds).squeeze().view(-1).mean()\n",
    "        _, y_hat = log_p_y.max(2)\n",
    "        acc_val = torch.eq(y_hat, target_inds.squeeze()).float().mean()\n",
    "\n",
    "        return loss_val, {\n",
    "            'loss': loss_val.item(),\n",
    "            'acc': acc_val.item(),\n",
    "            'y_hat': y_hat\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7783fa32-a79d-44a9-a5dc-8682bebce0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50daa90c-e740-436c-b292-8e15a3935081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f6f716-6be1-4551-9839-f4c22c9e6a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4e4a41-8d14-4faa-9116-5e4a855e62d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def euclidean_dist(x, y):\n",
    "    \"\"\"\n",
    "    Compute euclidean distance between two tensors\n",
    "    Args:\n",
    "        x (torch.Tensor): shape (n, d). n usually n_way*n_query\n",
    "        y (torch.Tensor): shape (m, d). m usually n_way\n",
    "    Returns:\n",
    "        torch.Tensor: shape(n, m). For each query, the distances to each centroid\n",
    "    \"\"\"\n",
    "    n = x.size(0)\n",
    "    m = y.size(0)\n",
    "    d = x.size(1)\n",
    "    assert d == y.size(1)\n",
    "\n",
    "    x = x.unsqueeze(1).expand(n, m, d)\n",
    "    y = y.unsqueeze(0).expand(n, m, d)\n",
    "\n",
    "    return torch.pow(x - y, 2).sum(2)\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class ProtoNet(nn.Module):\n",
    "    def __init__(self, encoder):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            encoder : CNN encoding the EEG samples\n",
    "            n_way (int): number of classes in a classification task\n",
    "            n_support (int): number of labeled examples per class in the support set\n",
    "            n_query (int): number of labeled examples per class in the query set\n",
    "        \"\"\"\n",
    "        super(ProtoNet, self).__init__()\n",
    "        self.encoder = encoder.cuda()\n",
    "\n",
    "    def set_forward_loss(self, sample):\n",
    "        \"\"\"\n",
    "        Computes loss, accuracy and output for classification task\n",
    "        Args:\n",
    "            sample (torch.Tensor): shape (n_way, n_support+n_query, (dim)) \n",
    "        Returns:\n",
    "            torch.Tensor: shape(2), loss, accuracy and y_hat\n",
    "        \"\"\"\n",
    "        sample_EEG = sample['EEG'].cuda()\n",
    "        n_way = sample['n_way']\n",
    "        n_support = sample['n_support']\n",
    "        n_query = sample['n_query']\n",
    "\n",
    "        x_support = sample_EEG[:, :n_support]\n",
    "        x_query = sample_EEG[:, n_support:]\n",
    "\n",
    "        # target indices are 0 ... n_way-1\n",
    "        target_inds = torch.arange(0, n_way).view(n_way, 1, 1).expand(n_way, n_query, 1).long()\n",
    "        target_inds = Variable(target_inds, requires_grad=False)\n",
    "        target_inds = target_inds.cuda()\n",
    "\n",
    "        # encode EEG samples of the support and the query set\n",
    "        x = torch.cat([x_support.contiguous().view(n_way * n_support, *x_support.size()[2:]),\n",
    "                       x_query.contiguous().view(n_way * n_query, *x_query.size()[2:])], 0)\n",
    "\n",
    "        z = self.encoder.forward(x)\n",
    "        z_dim = z.size(-1)  # usually 64\n",
    "        z_proto = z[:n_way*n_support].view(n_way, n_support, z_dim).mean(1)\n",
    "        z_query = z[n_way*n_support:]\n",
    "\n",
    "        # compute distances\n",
    "        dists = euclidean_dist(z_query, z_proto)\n",
    "\n",
    "        # compute probabilities\n",
    "        log_p_y = F.log_softmax(-dists, dim=1).view(n_way, n_query, -1)\n",
    "\n",
    "        loss_val = -log_p_y.gather(2, target_inds).squeeze().view(-1).mean()\n",
    "        _, y_hat = log_p_y.max(2)\n",
    "        acc_val = torch.eq(y_hat, target_inds.squeeze()).float().mean()\n",
    "\n",
    "        return loss_val, {\n",
    "            'loss': loss_val.item(),\n",
    "            'acc': acc_val.item(),\n",
    "            'y_hat': y_hat\n",
    "        }\n",
    "\n",
    "def load_protonet_conv(**kwargs):\n",
    "    \"\"\"\n",
    "    Loads the prototypical network model\n",
    "    Arg:\n",
    "        x_dim (tuple): dimension of input EEG data (channels, length)\n",
    "        hid_dim (int): dimension of hidden layers in conv blocks\n",
    "        z_dim (int): dimension of embedded EEG data\n",
    "    Returns:\n",
    "        Model (Class ProtoNet)\n",
    "    \"\"\"\n",
    "    x_dim = kwargs['x_dim']\n",
    "    hid_dim = kwargs['hid_dim']\n",
    "    z_dim = kwargs['z_dim']\n",
    "\n",
    "    def conv_block(in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2)\n",
    "        )\n",
    "    \n",
    "    encoder = nn.Sequential(\n",
    "        conv_block(x_dim[0], hid_dim),\n",
    "        conv_block(hid_dim, hid_dim),\n",
    "        conv_block(hid_dim, hid_dim),\n",
    "        conv_block(hid_dim, z_dim),\n",
    "        Flatten()\n",
    "    )\n",
    "    \n",
    "    return ProtoNet(encoder)\n",
    "\n",
    "# Example usage:\n",
    "x_dim = (5, 128)  # Assuming 5 channels and 128 length for the EEG data\n",
    "hid_dim = 64\n",
    "z_dim = 64\n",
    "\n",
    "model = load_protonet_conv(x_dim=x_dim, hid_dim=hid_dim, z_dim=z_dim)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d8f4d1-870f-40be-be58-de222cb3d5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31444043-28e0-42fa-a9a5-7b0263d2a301",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 127] The specified procedure could not be found. Error loading \"C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIs CUDA supported by this system? \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\torch\\__init__.py:132\u001b[0m\n\u001b[0;32m    130\u001b[0m     err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(last_error)\n\u001b[0;32m    131\u001b[0m     err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 132\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 127] The specified procedure could not be found. Error loading \"C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Storing ID of current CUDA device\n",
    "    cuda_id = torch.cuda.current_device()\n",
    "    print(f\"ID of current CUDA device: {cuda_id}\")\n",
    "\n",
    "    print(f\"Name of current CUDA device: {torch.cuda.get_device_name(cuda_id)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available on this system.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f2f6b8-8e7b-4a65-aa36-810c51849deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfaed34-429c-4547-8c98-3c11168e495f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2928c56-3c0f-4ea6-a6b9-7dabddffc277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24917406-1333-4cbf-9907-c240e7157588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bdd6fa-3dad-41e9-883f-be29774b7a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5001d827-a749-4221-8188-7cf0a8f69f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3cf24b-4a37-46c2-82fd-ae4b0b077cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc13ede-fdf2-4cf6-9126-ba410443abc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fd4afc-45cc-4f2e-ad95-3ddccfc546ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ec9653-8a15-4f36-be4c-52ea60a74401",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
